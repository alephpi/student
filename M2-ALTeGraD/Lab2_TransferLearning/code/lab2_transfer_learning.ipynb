{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlAfI8mCWAf3"
   },
   "source": [
    "<center><h2>ALTeGraD 2022<br>Lab Session 2: Transfer learning for NLP</h2> 27 / 10 / 2022<br> M. Kamal Eddine, H. Abdine<br><br>\n",
    "\n",
    "\n",
    "<b>Student name:</b> Sicheng MAO\n",
    "\n",
    "</center>\n",
    "\n",
    "<br><br>\n",
    "In this lab we will:\n",
    "* Implement and pretrain a language model with transformer architecture.\n",
    "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
    "* Compare the performance of the pretrained model to a model trained from scratch.\n",
    " <br>\n",
    " \n",
    "<b>The deadline for this lab is November 14, 2022 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IqukuIe0Rb_c"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FF6fjkqgN39"
   },
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "p0cj9WkSFQwl"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        '''\n",
    "        ntokens: the size of vocabulary\n",
    "        nhid: the hidden dimension of the model.\n",
    "        We assume that embedding_dim = nhid\n",
    "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "        nhead: the number of heads in the multiheadattention models\n",
    "        dropout: the dropout value\n",
    "         '''\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.encoder = nn.Embedding(num_embeddings = ntoken, embedding_dim = nhid) # fill me, nhid = the dim_embed\n",
    "        self.pos_encoder = PositionalEncoding(nhid=nhid) #fill me, the PositionalEncoding class is implemented in the next cell\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model = nhid, nhead = nhead, dim_feedforward = nhid, dropout = dropout) #fill me we assume nhid = d_model = dim_feedforward\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers = nlayers) #fill me\n",
    "        self.nhid = nhid\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = (\n",
    "            mask.float()\n",
    "            .masked_fill(mask == 0, float(\"-inf\"))\n",
    "            .masked_fill(mask == 1, float(0.0))\n",
    "        )\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        '''\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        '''\n",
    "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        return output\n",
    "\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, nhid, nclasses):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.decoder = nn.Linear(nhid, nclasses)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        output = self.decoder(src)\n",
    "        return output\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
    "        super(Model, self).__init__()\n",
    "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers)\n",
    "        self.classifier = ClassificationHead(nhid, nclasses)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        # base model\n",
    "        x = self.base(src, src_mask)\n",
    "        # classifier model\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kt2QQohaFZry"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, nhid)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfEYHJx2JW6l"
   },
   "source": [
    "Let's verify if our model works, by applying one inference step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhb2gkUhJMR0",
    "outputId": "7760859d-44ee-469f-cb9d-2a589b0a6a13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 100])\n"
     ]
    }
   ],
   "source": [
    "ntokens = 100 # the size of vocabulary\n",
    "nhid = 200  # hidden dimension\n",
    "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # the number of heads in the multiheadattention models\n",
    "dropout = 0  # the dropout value\n",
    "\n",
    "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
    "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
    "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
    "out = model.forward(dummy_input, src_mask)\n",
    "\n",
    "print(out.shape) # is it the right shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iB_DNThorKhH",
    "outputId": "c75c7a13-8ff1-4033-b4bb-bb13ee493b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.7138, -0.1413,  0.2734,  2.4253, -0.5079,  0.2122, -1.4434, -0.4653,\n",
      "        -0.9514,  1.6774, -0.7325,  1.0488,  0.9989,  1.5706,  0.7859,  0.1369,\n",
      "         1.2027,  0.3692,  0.4479, -1.0119, -0.0792, -0.1049,  0.1175, -1.2617,\n",
      "        -1.4365, -0.5686, -0.1960,  0.1295,  0.3498,  0.6875,  0.2201,  0.2695,\n",
      "        -1.1672,  0.5189, -1.2647,  0.1727, -0.3303, -1.3664,  0.1682, -2.3528,\n",
      "        -0.2755, -1.4338, -1.0979, -0.5085,  1.6198, -0.3388, -0.7955, -0.4648,\n",
      "         0.0186,  0.0108, -0.8273,  0.5023,  0.0048, -0.4990,  0.2525,  0.0321,\n",
      "        -0.5266, -0.7469, -0.4956,  0.3952,  1.4615,  0.0521, -0.7608,  1.1481,\n",
      "        -0.3321, -0.7071,  0.3510, -0.8542, -0.6793, -0.4115,  0.1402, -0.8882,\n",
      "        -0.3408,  1.0072, -0.4910, -0.2398, -0.0436, -1.2243,  2.0696,  2.5848,\n",
      "        -0.6041,  1.0915, -0.4513,  0.4450,  0.0124, -0.7892, -0.5172,  1.3586,\n",
      "         0.4681,  0.6004, -1.6136,  2.4900, -1.3775, -1.2326,  0.0569,  0.0483,\n",
      "        -0.8962,  1.2532,  1.2661,  0.8094], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(out[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i74NN897Fcit"
   },
   "source": [
    "## Vocabulary and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qjd26ghWuff",
    "outputId": "d4cb4ec5-9acf-4e8c-e096-d073be9b9ae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-05 09:06:49--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 577587 (564K) [text/plain]\n",
      "Saving to: 'dict.txt.1'\n",
      "\n",
      "dict.txt.1          100%[===================>] 564.05K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2022-11-05 09:06:49 (11.8 MB/s) - 'dict.txt.1' saved [577587/577587]\n",
      "\n",
      "▁d 1\n",
      "es 1\n",
      "▁l 1\n",
      "en 1\n",
      "on 1\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
    "!head -5 dict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFdH_-JeFbGA",
    "outputId": "0b787d22-a7eb-4837-abe0-471229c0832d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁trop\n"
     ]
    }
   ],
   "source": [
    "path_vocab = \"dict.txt\"\n",
    "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
    "with open(path_vocab, \"r\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        word = line.split()[0].strip()\n",
    "        token2ind[word] = idx + 4 #fill me\n",
    "\n",
    "ind2token = {idx: word for (word, idx) in token2ind.items()} #fill me\n",
    "\n",
    "print(ind2token[1111])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOExGODajN8p"
   },
   "source": [
    "### Data Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2ZgqXTgrKhK",
    "outputId": "25b3f5de-9bee-4380-a9b7-64e2f13a4839"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2ind.get('=',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Y0jN-Ar9i5Q1"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        path_documents,\n",
    "        path_labels=None,\n",
    "        token2ind={},\n",
    "        max_len=512,\n",
    "        task=\"language_modeling\",\n",
    "    ):\n",
    "        self.task = task\n",
    "        self.max_len = max_len\n",
    "        self.token2ind = token2ind\n",
    "        self.documents = []\n",
    "        self.labels = []\n",
    "        with open(path_documents, \"r\") as f1:\n",
    "            for line in f1:\n",
    "                self.documents.append(line.strip())\n",
    "        if task == \"classification\":\n",
    "            with open(path_labels, \"r\") as f1:\n",
    "                for line in f1:\n",
    "                    self.labels.append(int(line.strip()))\n",
    "            assert len(self.labels) == len(self.documents)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.documents)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sequence = self.documents[index].split()\n",
    "        if len(sequence) > self.max_len - 1:\n",
    "            sequence = sequence[: self.max_len - 1]\n",
    "        # <oov> index is 3\n",
    "        source_sequence =  [token2ind.get(token, 3) for token in sequence]#fill me (constract the input sequence using token2ind, sequence and special tokens)\n",
    "        if self.task == \"language_modeling\":\n",
    "            target = source_sequence[1:]\n",
    "            target.append(self.token2ind[\"<eos>\"])\n",
    "        elif self.task == \"classification\":\n",
    "            target = [self.labels[index]]\n",
    "        sample = {\n",
    "            \"source_sequence\": torch.tensor(source_sequence),\n",
    "            \"target\": torch.tensor(target),\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "\n",
    "def MyCollator(batch):\n",
    "    source_sequences = pad_sequence(\n",
    "        #we use padding to match the length of the sequences in the same batch\n",
    "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
    "    )\n",
    "    target = pad_sequence(\n",
    "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
    "    )\n",
    "    return source_sequences, target.reshape(-1)\n",
    "\n",
    "\n",
    "def get_loader(\n",
    "    path_documents,\n",
    "    path_labels=None,\n",
    "    token2ind={},\n",
    "    max_len=512,\n",
    "    batch_size=32,\n",
    "    task=\"language_modeling\",\n",
    "):\n",
    "    dataset = Dataset(\n",
    "        path_documents,\n",
    "        path_labels=path_labels,\n",
    "        token2ind=token2ind,\n",
    "        max_len=512,\n",
    "        task=task,\n",
    "    )\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=MyCollator,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTns4lHrjUTa"
   },
   "source": [
    "## The Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gsSmGFujrKhM"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4_jwosiLjRsS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    path_data_train,\n",
    "    path_labels_train=None,\n",
    "    path_data_valid=None,\n",
    "    save_interval=-1,\n",
    "    log_interval=5,\n",
    "    task=\"language_modeling\",\n",
    "    batch_size=32,\n",
    "):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    ntokens = len(token2ind)\n",
    "    data_loader = get_loader(\n",
    "        path_data_train,\n",
    "        path_labels_train,\n",
    "        token2ind,\n",
    "        task=task,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    losses = []\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(data_loader), total=len(data_loader)): #step 1\n",
    "        optimizer.zero_grad()\n",
    "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(device)\n",
    "        # avoid using input since it is a built-in function\n",
    "        input_data = data[0].to(device)\n",
    "        # print(input_data.shape)\n",
    "        output = model(input_data, src_mask) #step 2\n",
    "        # print(output.shape)\n",
    "        if task == 'classification':\n",
    "            #last vector only, is the distribution on two classes\n",
    "            output = output[-1,:]\n",
    "            pass\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        # print(output)\n",
    "        target = data[1] #fill me\n",
    "        # print(target)\n",
    "        target = target.to(device)\n",
    "        loss = criterion(output, target) #fill me, Cross entropy check next cells\n",
    "        #fill me step 3\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient \n",
    "        #fill me step 4\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() \n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
    "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
    "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
    "                )\n",
    "            )\n",
    "            losses.append(cur_loss)\n",
    "            total_loss = 0\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pgf6BDB9jUr6"
   },
   "outputs": [],
   "source": [
    "ntokens = len(token2ind) #fill me # the size of vocabulary\n",
    "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # the number of heads in the multiheadattention models\n",
    "dropout = 0  # the dropout value\n",
    "\n",
    "nclasses = 2 # for classification task only\n",
    "\n",
    "#notice here that the nclasses argument = ntokens (for language modeling task, we predict the next token)\n",
    "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "u-OLy4KIkDwf"
   },
   "outputs": [],
   "source": [
    "# optimization paramerters\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
    "lr = 0.0003  # learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bwh3n9xZQy4e",
    "outputId": "63be795b-b7d1-4e7a-946f-c85dae500678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-05 09:06:50--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10146460 (9.7M) [text/plain]\n",
      "Saving to: 'pretraining_subset.txt.1'\n",
      "\n",
      "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2022-11-05 09:06:50 (94.3 MB/s) - 'pretraining_subset.txt.1' saved [10146460/10146460]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
    "path_data_train = \"pretraining_subset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kgx63TwarKhO",
    "outputId": "6abeea2a-0fa8-45af-f945-1c0a89c9b371"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0m11g4ScjZaR",
    "outputId": "85cde9b4-1ef2-43a3-ec70-97b7433e8f34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 502/3125 [00:24<01:56, 22.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 3125 steps | loss 7.59751 | ppl 1993.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1003/3125 [00:50<01:41, 20.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1000/ 3125 steps | loss 6.85649 | ppl  950.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1502/3125 [01:15<01:21, 19.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1500/ 3125 steps | loss 6.54952 | ppl  698.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2002/3125 [01:40<00:50, 22.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2000/ 3125 steps | loss 6.37271 | ppl  585.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2503/3125 [02:06<00:35, 17.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2500/ 3125 steps | loss 6.22746 | ppl  506.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 3005/3125 [02:33<00:05, 22.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  3000/ 3125 steps | loss 6.15350 | ppl  470.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [02:39<00:00, 19.63it/s]\n",
      " 16%|█▌        | 503/3125 [00:25<02:02, 21.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   500/ 3125 steps | loss 5.85538 | ppl  349.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1005/3125 [00:51<01:40, 21.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1000/ 3125 steps | loss 5.79816 | ppl  329.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1506/3125 [01:18<01:16, 21.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1500/ 3125 steps | loss 5.76633 | ppl  319.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2003/3125 [01:44<01:02, 17.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  2000/ 3125 steps | loss 5.68995 | ppl  295.880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2505/3125 [02:10<00:30, 20.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  2500/ 3125 steps | loss 5.66414 | ppl  288.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 3004/3125 [02:37<00:06, 18.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  3000/ 3125 steps | loss 5.64214 | ppl  282.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [02:44<00:00, 19.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#pretraining on a tiny subset\n",
    "log_interval = 500\n",
    "epochs = 2\n",
    "for epoch in range(1, epochs + 1): #5\n",
    "    train(\n",
    "        path_data_train,\n",
    "        save_interval=-1,\n",
    "        task='language_modeling', # fill me\n",
    "        batch_size=16,\n",
    "        log_interval=log_interval,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_3t4QZu8cma",
    "outputId": "67d66624-58f6-46e7-97fd-533c5095f79c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (base): TransformerModel(\n",
      "    (encoder): Embedding(50001, 200)\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=200, out_features=200, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=200, out_features=200, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=200, out_features=200, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=200, out_features=200, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ClassificationHead(\n",
      "    (decoder): Linear(in_features=200, out_features=50001, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5mW63_O7PEr",
    "outputId": "58257f68-7c00-47e0-c2c8-0111a82df3a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50001 * 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e10-yaRi6TXG",
    "outputId": "f3a06243-631f-4c4a-a90f-b858fe1a0017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base.encoder.weight torch.Size([50001, 200]) True\n",
      "base.transformer_encoder.layers.0.self_attn.in_proj_weight torch.Size([600, 200]) True\n",
      "base.transformer_encoder.layers.0.self_attn.in_proj_bias torch.Size([600]) True\n",
      "base.transformer_encoder.layers.0.self_attn.out_proj.weight torch.Size([200, 200]) True\n",
      "base.transformer_encoder.layers.0.self_attn.out_proj.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.0.linear1.weight torch.Size([200, 200]) True\n",
      "base.transformer_encoder.layers.0.linear1.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.0.linear2.weight torch.Size([200, 200]) True\n",
      "base.transformer_encoder.layers.0.linear2.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.0.norm1.weight torch.Size([200]) True\n",
      "base.transformer_encoder.layers.0.norm1.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.0.norm2.weight torch.Size([200]) True\n",
      "base.transformer_encoder.layers.0.norm2.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.1.self_attn.in_proj_weight torch.Size([600, 200]) True\n",
      "base.transformer_encoder.layers.1.self_attn.in_proj_bias torch.Size([600]) True\n",
      "base.transformer_encoder.layers.1.self_attn.out_proj.weight torch.Size([200, 200]) True\n",
      "base.transformer_encoder.layers.1.self_attn.out_proj.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.1.linear1.weight torch.Size([200, 200]) True\n",
      "base.transformer_encoder.layers.1.linear1.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.1.linear2.weight torch.Size([200, 200]) True\n",
      "base.transformer_encoder.layers.1.linear2.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.1.norm1.weight torch.Size([200]) True\n",
      "base.transformer_encoder.layers.1.norm1.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.1.norm2.weight torch.Size([200]) True\n",
      "base.transformer_encoder.layers.1.norm2.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.2.self_attn.in_proj_weight torch.Size([600, 200]) True\n",
      "base.transformer_encoder.layers.2.self_attn.in_proj_bias torch.Size([600]) True\n",
      "base.transformer_encoder.layers.2.self_attn.out_proj.weight torch.Size([200, 200]) True\n",
      "base.transformer_encoder.layers.2.self_attn.out_proj.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.2.linear1.weight torch.Size([200, 200]) True\n",
      "base.transformer_encoder.layers.2.linear1.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.2.linear2.weight torch.Size([200, 200]) True\n",
      "base.transformer_encoder.layers.2.linear2.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.2.norm1.weight torch.Size([200]) True\n",
      "base.transformer_encoder.layers.2.norm1.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.2.norm2.weight torch.Size([200]) True\n",
      "base.transformer_encoder.layers.2.norm2.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.3.self_attn.in_proj_weight torch.Size([600, 200]) True\n",
      "base.transformer_encoder.layers.3.self_attn.in_proj_bias torch.Size([600]) True\n",
      "base.transformer_encoder.layers.3.self_attn.out_proj.weight torch.Size([200, 200]) True\n",
      "base.transformer_encoder.layers.3.self_attn.out_proj.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.3.linear1.weight torch.Size([200, 200]) True\n",
      "base.transformer_encoder.layers.3.linear1.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.3.linear2.weight torch.Size([200, 200]) True\n",
      "base.transformer_encoder.layers.3.linear2.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.3.norm1.weight torch.Size([200]) True\n",
      "base.transformer_encoder.layers.3.norm1.bias torch.Size([200]) True\n",
      "base.transformer_encoder.layers.3.norm2.weight torch.Size([200]) True\n",
      "base.transformer_encoder.layers.3.norm2.bias torch.Size([200]) True\n",
      "classifier.decoder.weight torch.Size([50001, 200]) True\n",
      "classifier.decoder.bias torch.Size([50001]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "  print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeOM1dOvkO4e"
   },
   "source": [
    "## Text Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BcBC6FSkMH3",
    "outputId": "151a0128-1beb-4e9d-8b9e-3595eeb1c999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-05 09:12:14--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 88093955 (84M) [application/octet-stream]\n",
      "Saving to: 'pretrained_model_4layers.pt.1'\n",
      "\n",
      "pretrained_model_4l 100%[===================>]  84.01M   195MB/s    in 0.4s    \n",
      "\n",
      "2022-11-05 09:12:15 (195 MB/s) - 'pretrained_model_4layers.pt.1' saved [88093955/88093955]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BcBC6FSkMH3",
    "outputId": "151a0128-1beb-4e9d-8b9e-3595eeb1c999"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device) \n",
    "\n",
    "#load the checkpoint\n",
    "checkpoint = torch.load('pretrained_model_4layers.pt', map_location=device)\n",
    "#load state dict\n",
    "model.load_state_dict(checkpoint['model_state_dict']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tBRRVsWqlIoQ",
    "outputId": "b48a5ed4-cfe2-4219-f279-9319ac61af0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (0.1.97)\n",
      "--2022-11-05 09:12:18--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115362 (1.1M) [application/octet-stream]\n",
      "Saving to: 'sentencepiece.french.model.1'\n",
      "\n",
      "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2022-11-05 09:12:18 (17.8 MB/s) - 'sentencepiece.french.model.1' saved [1115362/1115362]\n",
      "\n",
      "['▁Bonjour', '▁les', '▁amis', '!']\n",
      "Bonjour les amis!\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece   # uncomment this if you are using google colab\n",
    "\n",
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
    "\n",
    "#examples\n",
    "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
    "decoded = s.decode_pieces(encoded)\n",
    "print(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "id": "TtLlV05pkQI3",
    "outputId": "8aef1253-12c1-4842-f94c-e6a268555d34"
   },
   "outputs": [],
   "source": [
    "def infer_next_token(sent):\n",
    "    model.eval()\n",
    "    sent_pieces = s.encode_as_pieces(sent)\n",
    "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
    "    source = torch.tensor(source).to(device)\n",
    "    source = source.reshape(-1, 1)\n",
    "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
    "    out = model(source, src_mask)\n",
    "    next_token_ind = out[-1].squeeze().argmax().item() # the last hidden state\n",
    "    return next_token_ind, out\n",
    "\n",
    "def infer_next_tokens(sent, max_len=50):\n",
    "    # to be implemented\n",
    "    tokens = s.encode_as_pieces(sent)\n",
    "    sent_gen = sent  # sent is a normal sentence\n",
    "    for i in range(max_len):\n",
    "        next_token_ind, _ = infer_next_token(sent_gen)\n",
    "        cur_token = ind2token[next_token_ind]\n",
    "        if cur_token == '<eos>':\n",
    "            break\n",
    "        else:\n",
    "            tokens.append(cur_token)\n",
    "            sent_gen = s.decode_pieces(tokens)\n",
    "    \n",
    "    return sent_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Bonjour les\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1696\n"
     ]
    }
   ],
   "source": [
    "ind, out = infer_next_token(sent)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 50001])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.argmax(axis = 2).squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁Il\n",
      ",\n",
      "▁gens\n"
     ]
    }
   ],
   "source": [
    "for ind in out:\n",
    "    token = ind2token[ind]\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gens'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.decode_pieces(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1696"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2ind[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means given `<sos>` the next token is `Il`,\n",
    "given `<sos> Bonjour` the next token is `,`,\n",
    "given `<sos> Bonjour les` the next token is `gens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "f83Nn5nSly4v"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour les gens qui ont été très accueillants et sympathiques.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_next_tokens(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop seems strange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je t'aime bien les gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_next_tokens(\"Je t'aime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok Artificial Ignorance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bien les gens ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont des gens qui ont'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_next_tokens(\"Bien les gens ont des gens qui ont des gens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp7mjVzomoZ3",
    "tags": []
   },
   "source": [
    "### Supervised task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "0K1BZsblmEmx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-05 09:12:19--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1495960 (1.4M) [text/plain]\n",
      "Saving to: 'train.review.spm.1'\n",
      "\n",
      "train.review.spm.1  100%[===================>]   1.43M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2022-11-05 09:12:19 (22.3 MB/s) - 'train.review.spm.1' saved [1495960/1495960]\n",
      "\n",
      "--2022-11-05 09:12:19--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3200 (3.1K) [text/plain]\n",
      "Saving to: 'train.label.1'\n",
      "\n",
      "train.label.1       100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-11-05 09:12:19 (60.7 MB/s) - 'train.label.1' saved [3200/3200]\n",
      "\n",
      "--2022-11-05 09:12:19--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1864544 (1.8M) [text/plain]\n",
      "Saving to: 'test.review.spm.1'\n",
      "\n",
      "test.review.spm.1   100%[===================>]   1.78M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2022-11-05 09:12:20 (27.2 MB/s) - 'test.review.spm.1' saved [1864544/1864544]\n",
      "\n",
      "--2022-11-05 09:12:20--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4000 (3.9K) [text/plain]\n",
      "Saving to: 'test.label.1'\n",
      "\n",
      "test.label.1        100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-11-05 09:12:20 (74.2 MB/s) - 'test.label.1' saved [4000/4000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
    "\n",
    "path_data_train = \"train.review.spm\"\n",
    "path_labels_train = \"train.label\"\n",
    "\n",
    "path_data_valid = \"test.review.spm\"\n",
    "path_labels_valid = \"test.label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_MLfvjiom2SL"
   },
   "outputs": [],
   "source": [
    "# a function to evaluate the validation accuracy of the model.\n",
    "# adapt from lab1 and train()\n",
    "def evaluate_accuracy(data_loader):\n",
    "    #to be implemented\n",
    "    model.eval()\n",
    "    # total_loss = 0.0\n",
    "    ncorrect = ntotal = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, data in tqdm(enumerate(data_loader),total=len(data_loader)):\n",
    "            src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(device)\n",
    "            # inference\n",
    "            input_data = data[0].to(device)\n",
    "            output = model(input_data, src_mask)\n",
    "            #last vector only, is the distribution on two classes\n",
    "            output = output[-1,:]\n",
    "            output = output.view(-1, output.shape[-1])\n",
    "            prediction = output.argmax(axis=-1)\n",
    "            # print(output)\n",
    "            target = data[1].to(device)\n",
    "            # total number of examples\n",
    "            ntotal += output.shape[0]\n",
    "            # number of correct predictions\n",
    "            ncorrect += torch.sum(target == prediction)  # number of correct prediction - hint: use torch.sum \n",
    "        acc = ncorrect.item() / ntotal\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "qzmx7T7xoa6v"
   },
   "outputs": [],
   "source": [
    "#save the base model to be loaded later in the fine-tuning phase\n",
    "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "o = torch.tensor([[-1.1873, -0.4178],\n",
    "        [-0.3639, -1.1610],\n",
    "        [-0.7206,  0.4625],\n",
    "        [-0.9607,  0.4202],\n",
    "        [-1.6203,  0.6857],\n",
    "        [ 0.2038, -0.8536],\n",
    "        [-0.0487, -0.6102],\n",
    "        [-0.2580,  0.0405]])\n",
    "t = torch.tensor([0, 0, 0, 1, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3434)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(o,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "i-xclMCpnVpw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Trainig FROM SCRATCH======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/200 [00:01<00:03, 39.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  200 steps | loss 0.81389 | ppl    2.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 110/200 [00:02<00:02, 42.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   100/  200 steps | loss 0.75189 | ppl    2.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 155/200 [00:03<00:01, 41.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   150/  200 steps | loss 0.73675 | ppl    2.089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.01it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 49.37it/s]\n",
      " 30%|██▉       | 59/200 [00:01<00:03, 41.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |    50/  200 steps | loss 0.72843 | ppl    2.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 103/200 [00:02<00:02, 40.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   100/  200 steps | loss 0.70847 | ppl    2.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [00:03<00:01, 41.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   150/  200 steps | loss 0.74535 | ppl    2.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:05<00:00, 39.95it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 49.20it/s]\n",
      " 30%|███       | 60/200 [00:01<00:03, 41.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |    50/  200 steps | loss 0.69252 | ppl    1.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [00:02<00:02, 40.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   100/  200 steps | loss 0.65605 | ppl    1.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 156/200 [00:03<00:00, 44.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   150/  200 steps | loss 0.65483 | ppl    1.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:05<00:00, 39.78it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.71it/s]\n",
      " 28%|██▊       | 57/200 [00:01<00:03, 40.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |    50/  200 steps | loss 0.41630 | ppl    1.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [00:02<00:02, 41.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   100/  200 steps | loss 0.36603 | ppl    1.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 155/200 [00:03<00:01, 37.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   150/  200 steps | loss 0.35458 | ppl    1.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.02it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 49.57it/s]\n",
      " 28%|██▊       | 56/200 [00:01<00:03, 38.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |    50/  200 steps | loss 0.20672 | ppl    1.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [00:02<00:02, 40.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   100/  200 steps | loss 0.14315 | ppl    1.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [00:04<00:01, 39.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   150/  200 steps | loss 0.19953 | ppl    1.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:05<00:00, 38.82it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.71it/s]\n",
      " 30%|██▉       | 59/200 [00:01<00:03, 45.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |    50/  200 steps | loss 0.08072 | ppl    1.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [00:02<00:02, 43.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |   100/  200 steps | loss 0.07277 | ppl    1.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 156/200 [00:03<00:01, 38.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |   150/  200 steps | loss 0.07037 | ppl    1.073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 41.40it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.42it/s]\n",
      " 28%|██▊       | 56/200 [00:01<00:03, 41.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   7 |    50/  200 steps | loss 0.01944 | ppl    1.020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 107/200 [00:02<00:02, 43.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   7 |   100/  200 steps | loss 0.02582 | ppl    1.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 156/200 [00:03<00:01, 43.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   7 |   150/  200 steps | loss 0.05165 | ppl    1.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.93it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 47.69it/s]\n",
      " 29%|██▉       | 58/200 [00:01<00:03, 38.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   8 |    50/  200 steps | loss 0.00136 | ppl    1.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [00:02<00:02, 39.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   8 |   100/  200 steps | loss 0.05754 | ppl    1.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 158/200 [00:03<00:00, 44.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   8 |   150/  200 steps | loss 0.03368 | ppl    1.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.56it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.62it/s]\n",
      " 27%|██▋       | 54/200 [00:01<00:03, 38.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   9 |    50/  200 steps | loss 0.02250 | ppl    1.023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [00:02<00:02, 36.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   9 |   100/  200 steps | loss 0.02743 | ppl    1.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 158/200 [00:03<00:00, 43.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   9 |   150/  200 steps | loss 0.01507 | ppl    1.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.80it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 49.56it/s]\n",
      " 30%|███       | 60/200 [00:01<00:03, 43.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  10 |    50/  200 steps | loss 0.02056 | ppl    1.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [00:02<00:02, 42.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  10 |   100/  200 steps | loss 0.00013 | ppl    1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 156/200 [00:03<00:01, 39.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  10 |   150/  200 steps | loss 0.00011 | ppl    1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 41.47it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 49.83it/s]\n",
      " 28%|██▊       | 56/200 [00:01<00:03, 41.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 |    50/  200 steps | loss 0.02198 | ppl    1.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [00:02<00:02, 39.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 |   100/  200 steps | loss 0.00630 | ppl    1.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [00:03<00:01, 38.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 |   150/  200 steps | loss 0.02975 | ppl    1.030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:05<00:00, 39.79it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 49.86it/s]\n",
      " 28%|██▊       | 55/200 [00:01<00:03, 39.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  12 |    50/  200 steps | loss 0.01576 | ppl    1.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [00:02<00:01, 47.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  12 |   100/  200 steps | loss 0.00022 | ppl    1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 155/200 [00:03<00:01, 39.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  12 |   150/  200 steps | loss 0.00006 | ppl    1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 41.16it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.35it/s]\n",
      " 29%|██▉       | 58/200 [00:01<00:03, 39.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  13 |    50/  200 steps | loss 0.00004 | ppl    1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 108/200 [00:02<00:02, 40.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  13 |   100/  200 steps | loss 0.00004 | ppl    1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 155/200 [00:03<00:01, 43.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  13 |   150/  200 steps | loss 0.00379 | ppl    1.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.75it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 48.86it/s]\n",
      " 28%|██▊       | 55/200 [00:01<00:03, 39.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  14 |    50/  200 steps | loss 0.00945 | ppl    1.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [00:02<00:02, 38.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  14 |   100/  200 steps | loss 0.01014 | ppl    1.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 158/200 [00:03<00:00, 43.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  14 |   150/  200 steps | loss 0.00020 | ppl    1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 41.63it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 51.08it/s]\n",
      " 29%|██▉       | 58/200 [00:01<00:03, 37.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  15 |    50/  200 steps | loss 0.00005 | ppl    1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 107/200 [00:02<00:02, 37.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  15 |   100/  200 steps | loss 0.01934 | ppl    1.020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [00:03<00:01, 39.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  15 |   150/  200 steps | loss 0.00004 | ppl    1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 42.03it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====PRETRAINED MODEL======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 55/200 [00:01<00:03, 37.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  200 steps | loss 0.92021 | ppl    2.510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 109/200 [00:02<00:02, 42.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   100/  200 steps | loss 0.77212 | ppl    2.164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [00:03<00:00, 43.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   150/  200 steps | loss 0.76073 | ppl    2.140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:05<00:00, 39.41it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.66it/s]\n",
      " 30%|███       | 61/200 [00:01<00:02, 49.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |    50/  200 steps | loss 0.62791 | ppl    1.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 107/200 [00:02<00:02, 41.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   100/  200 steps | loss 0.63735 | ppl    1.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [00:03<00:01, 38.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   150/  200 steps | loss 0.57513 | ppl    1.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.78it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 48.73it/s]\n",
      " 28%|██▊       | 56/200 [00:01<00:03, 42.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |    50/  200 steps | loss 0.54194 | ppl    1.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [00:02<00:02, 44.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   100/  200 steps | loss 0.45183 | ppl    1.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [00:03<00:01, 36.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   150/  200 steps | loss 0.51099 | ppl    1.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:05<00:00, 39.58it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.21it/s]\n",
      " 30%|███       | 60/200 [00:01<00:03, 45.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |    50/  200 steps | loss 0.43934 | ppl    1.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [00:02<00:02, 41.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   100/  200 steps | loss 0.44159 | ppl    1.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 159/200 [00:03<00:00, 41.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   150/  200 steps | loss 0.36504 | ppl    1.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.69it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 49.36it/s]\n",
      " 28%|██▊       | 56/200 [00:01<00:03, 38.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |    50/  200 steps | loss 0.30202 | ppl    1.353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 109/200 [00:02<00:02, 39.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   100/  200 steps | loss 0.37455 | ppl    1.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [00:03<00:01, 40.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   150/  200 steps | loss 0.33507 | ppl    1.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:05<00:00, 39.58it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 49.83it/s]\n",
      " 28%|██▊       | 56/200 [00:01<00:03, 38.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |    50/  200 steps | loss 0.26676 | ppl    1.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 108/200 [00:02<00:02, 42.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |   100/  200 steps | loss 0.38802 | ppl    1.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [00:03<00:01, 37.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |   150/  200 steps | loss 0.21707 | ppl    1.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:05<00:00, 39.88it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.29it/s]\n",
      " 28%|██▊       | 55/200 [00:01<00:03, 39.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   7 |    50/  200 steps | loss 0.15820 | ppl    1.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 107/200 [00:02<00:02, 38.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   7 |   100/  200 steps | loss 0.28901 | ppl    1.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [00:03<00:01, 39.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   7 |   150/  200 steps | loss 0.33475 | ppl    1.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.17it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.25it/s]\n",
      " 28%|██▊       | 55/200 [00:01<00:03, 42.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   8 |    50/  200 steps | loss 0.18194 | ppl    1.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [00:02<00:02, 38.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   8 |   100/  200 steps | loss 0.19428 | ppl    1.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 156/200 [00:03<00:01, 41.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   8 |   150/  200 steps | loss 0.26090 | ppl    1.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.42it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.31it/s]\n",
      " 28%|██▊       | 55/200 [00:01<00:04, 36.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   9 |    50/  200 steps | loss 0.16434 | ppl    1.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [00:02<00:02, 42.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   9 |   100/  200 steps | loss 0.18124 | ppl    1.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 156/200 [00:03<00:01, 41.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   9 |   150/  200 steps | loss 0.15018 | ppl    1.162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.80it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 51.47it/s]\n",
      " 29%|██▉       | 58/200 [00:01<00:03, 41.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  10 |    50/  200 steps | loss 0.15279 | ppl    1.165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [00:02<00:02, 41.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  10 |   100/  200 steps | loss 0.05767 | ppl    1.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 155/200 [00:03<00:01, 39.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  10 |   150/  200 steps | loss 0.17548 | ppl    1.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.80it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 51.32it/s]\n",
      " 28%|██▊       | 57/200 [00:01<00:03, 40.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 |    50/  200 steps | loss 0.08550 | ppl    1.089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 103/200 [00:02<00:02, 39.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 |   100/  200 steps | loss 0.21753 | ppl    1.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 156/200 [00:03<00:01, 41.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 |   150/  200 steps | loss 0.09563 | ppl    1.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.56it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.49it/s]\n",
      " 30%|██▉       | 59/200 [00:01<00:03, 40.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  12 |    50/  200 steps | loss 0.08286 | ppl    1.086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [00:02<00:02, 38.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  12 |   100/  200 steps | loss 0.14477 | ppl    1.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 161/200 [00:03<00:00, 48.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  12 |   150/  200 steps | loss 0.05997 | ppl    1.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 41.90it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 52.05it/s]\n",
      " 29%|██▉       | 58/200 [00:01<00:03, 40.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  13 |    50/  200 steps | loss 0.09342 | ppl    1.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 109/200 [00:02<00:02, 41.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  13 |   100/  200 steps | loss 0.05713 | ppl    1.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 156/200 [00:03<00:01, 40.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  13 |   150/  200 steps | loss 0.05339 | ppl    1.055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.65it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.69it/s]\n",
      " 29%|██▉       | 58/200 [00:01<00:03, 41.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  14 |    50/  200 steps | loss 0.07765 | ppl    1.081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 107/200 [00:02<00:02, 39.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  14 |   100/  200 steps | loss 0.08469 | ppl    1.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 155/200 [00:03<00:01, 42.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  14 |   150/  200 steps | loss 0.01281 | ppl    1.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.79it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 51.43it/s]\n",
      " 29%|██▉       | 58/200 [00:01<00:03, 40.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  15 |    50/  200 steps | loss 0.05591 | ppl    1.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 110/200 [00:02<00:02, 42.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  15 |   100/  200 steps | loss 0.05679 | ppl    1.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [00:03<00:01, 42.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  15 |   150/  200 steps | loss 0.10679 | ppl    1.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 41.50it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 51.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from_scratch_settings = [True, False]\n",
    "\n",
    "from_scratch_valid_acc = []\n",
    "pretrained_valid_acc = []\n",
    "lr = 0.0001\n",
    "\n",
    "for from_scratch in from_scratch_settings:\n",
    "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    if not from_scratch:\n",
    "        print(\"=====PRETRAINED MODEL======\")\n",
    "        #load checkpoint\n",
    "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
    "        #load state dict\n",
    "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        print(\"=====Trainig FROM SCRATCH======\")\n",
    "    epochs = 15\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(\n",
    "            path_data_train,\n",
    "            path_labels_train,\n",
    "            save_interval=-1,\n",
    "            task='classification',\n",
    "            batch_size=8,\n",
    "            log_interval=50,\n",
    "        )\n",
    "        acc = evaluate_accuracy(\n",
    "            get_loader(\n",
    "                path_data_valid,\n",
    "                path_labels_valid,\n",
    "                token2ind=token2ind,\n",
    "                batch_size=20,\n",
    "                task='classification',\n",
    "            )\n",
    "        )\n",
    "        if from_scratch:\n",
    "            from_scratch_valid_acc.append(acc)\n",
    "        else:\n",
    "            pretrained_valid_acc.append(acc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.523,\n",
       " 0.5785,\n",
       " 0.703,\n",
       " 0.69,\n",
       " 0.76,\n",
       " 0.761,\n",
       " 0.7655,\n",
       " 0.757,\n",
       " 0.7705,\n",
       " 0.7645,\n",
       " 0.7595,\n",
       " 0.7635,\n",
       " 0.767,\n",
       " 0.763,\n",
       " 0.7305]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_scratch_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.706,\n",
       " 0.7645,\n",
       " 0.7795,\n",
       " 0.7825,\n",
       " 0.812,\n",
       " 0.806,\n",
       " 0.8025,\n",
       " 0.7925,\n",
       " 0.785,\n",
       " 0.78,\n",
       " 0.784,\n",
       " 0.781,\n",
       " 0.7835,\n",
       " 0.7795,\n",
       " 0.785]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "RCpBIdTHojm6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f562e9305b0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, epochs+1), from_scratch_valid_acc, label=\"from_scratch\")\n",
    "plt.plot(range(1, epochs+1), pretrained_valid_acc, label=\"pretrained\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "d2l:Python",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
